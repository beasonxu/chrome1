// components/ml/mojom/web_platform_model.mojom-blink.cc is auto generated by mojom_bindings_generator.py, do not edit

// Copyright 2013 The Chromium Authors. All rights reserved.
// Use of this source code is governed by a BSD-style license that can be
// found in the LICENSE file.

#if defined(__clang__)
#pragma clang diagnostic push
#pragma clang diagnostic ignored "-Wunused-private-field"
#endif

#include "components/ml/mojom/web_platform_model.mojom-blink.h"

#include <math.h>
#include <stdint.h>
#include <utility>

#include "base/debug/alias.h"
#include "base/hash/md5_constexpr.h"
#include "base/run_loop.h"
#include "base/strings/string_number_conversions.h"
#include "base/trace_event/trace_event.h"
#include "base/trace_event/typed_macros.h"
#include "mojo/public/cpp/bindings/lib/generated_code_util.h"
#include "mojo/public/cpp/bindings/lib/message_internal.h"
#include "mojo/public/cpp/bindings/lib/send_message_helper.h"
#include "mojo/public/cpp/bindings/lib/proxy_to_responder.h"
#include "mojo/public/cpp/bindings/lib/serialization_util.h"
#include "mojo/public/cpp/bindings/lib/unserialized_message_context.h"
#include "mojo/public/cpp/bindings/lib/validate_params.h"
#include "mojo/public/cpp/bindings/lib/validation_errors.h"
#include "mojo/public/cpp/bindings/mojo_buildflags.h"
#include "mojo/public/interfaces/bindings/interface_control_messages.mojom.h"
#include "third_party/perfetto/include/perfetto/tracing/traced_value.h"

#include "components/ml/mojom/web_platform_model.mojom-params-data.h"
#include "components/ml/mojom/web_platform_model.mojom-shared-message-ids.h"

#include "components/ml/mojom/web_platform_model.mojom-blink-import-headers.h"
#include "components/ml/mojom/web_platform_model.mojom-blink-test-utils.h"
#include "mojo/public/cpp/bindings/lib/wtf_serialization.h"


#ifndef COMPONENTS_ML_MOJOM_WEB_PLATFORM_MODEL_MOJOM_BLINK_JUMBO_H_
#define COMPONENTS_ML_MOJOM_WEB_PLATFORM_MODEL_MOJOM_BLINK_JUMBO_H_
#endif



namespace ml {
namespace model_loader {
namespace mojom {
namespace blink {
CreateModelLoaderOptions::CreateModelLoaderOptions()
    : num_threads(0U),
      model_format(),
      device_preference() {}

CreateModelLoaderOptions::CreateModelLoaderOptions(
    uint32_t num_threads_in,
    ModelFormat model_format_in,
    DevicePreference device_preference_in)
    : num_threads(std::move(num_threads_in)),
      model_format(std::move(model_format_in)),
      device_preference(std::move(device_preference_in)) {}

CreateModelLoaderOptions::~CreateModelLoaderOptions() = default;
size_t CreateModelLoaderOptions::Hash(size_t seed) const {
  seed = mojo::internal::WTFHash(seed, this->num_threads);
  seed = mojo::internal::WTFHash(seed, this->model_format);
  seed = mojo::internal::WTFHash(seed, this->device_preference);
  return seed;
}

void CreateModelLoaderOptions::WriteIntoTrace(
    perfetto::TracedValue traced_context) const {
  [[maybe_unused]] auto dict = std::move(traced_context).WriteDictionary();
  perfetto::WriteIntoTracedValueWithFallback(
    dict.AddItem(
      "num_threads"), this->num_threads,
#if BUILDFLAG(MOJO_TRACE_ENABLED)
      "<value of type uint32_t>"
#else
      "<value>"
#endif  // BUILDFLAG(MOJO_TRACE_ENABLED)
    );
  perfetto::WriteIntoTracedValueWithFallback(
    dict.AddItem(
      "model_format"), this->model_format,
#if BUILDFLAG(MOJO_TRACE_ENABLED)
      "<value of type ModelFormat>"
#else
      "<value>"
#endif  // BUILDFLAG(MOJO_TRACE_ENABLED)
    );
  perfetto::WriteIntoTracedValueWithFallback(
    dict.AddItem(
      "device_preference"), this->device_preference,
#if BUILDFLAG(MOJO_TRACE_ENABLED)
      "<value of type DevicePreference>"
#else
      "<value>"
#endif  // BUILDFLAG(MOJO_TRACE_ENABLED)
    );
}

bool CreateModelLoaderOptions::Validate(
    const void* data,
    mojo::internal::ValidationContext* validation_context) {
  return Data_::Validate(data, validation_context);
}
TensorInfo::TensorInfo()
    : byte_size(),
      data_type(),
      dimensions() {}

TensorInfo::TensorInfo(
    uint32_t byte_size_in,
    DataType data_type_in,
    WTF::Vector<uint32_t> dimensions_in)
    : byte_size(std::move(byte_size_in)),
      data_type(std::move(data_type_in)),
      dimensions(std::move(dimensions_in)) {}

TensorInfo::~TensorInfo() = default;

void TensorInfo::WriteIntoTrace(
    perfetto::TracedValue traced_context) const {
  [[maybe_unused]] auto dict = std::move(traced_context).WriteDictionary();
  perfetto::WriteIntoTracedValueWithFallback(
    dict.AddItem(
      "byte_size"), this->byte_size,
#if BUILDFLAG(MOJO_TRACE_ENABLED)
      "<value of type uint32_t>"
#else
      "<value>"
#endif  // BUILDFLAG(MOJO_TRACE_ENABLED)
    );
  perfetto::WriteIntoTracedValueWithFallback(
    dict.AddItem(
      "data_type"), this->data_type,
#if BUILDFLAG(MOJO_TRACE_ENABLED)
      "<value of type DataType>"
#else
      "<value>"
#endif  // BUILDFLAG(MOJO_TRACE_ENABLED)
    );
  perfetto::WriteIntoTracedValueWithFallback(
    dict.AddItem(
      "dimensions"), this->dimensions,
#if BUILDFLAG(MOJO_TRACE_ENABLED)
      "<value of type const WTF::Vector<uint32_t>&>"
#else
      "<value>"
#endif  // BUILDFLAG(MOJO_TRACE_ENABLED)
    );
}

bool TensorInfo::Validate(
    const void* data,
    mojo::internal::ValidationContext* validation_context) {
  return Data_::Validate(data, validation_context);
}
ModelInfo::ModelInfo()
    : input_tensor_info(),
      output_tensor_info() {}

ModelInfo::ModelInfo(
    WTF::HashMap<WTF::String, TensorInfoPtr> input_tensor_info_in,
    WTF::HashMap<WTF::String, TensorInfoPtr> output_tensor_info_in)
    : input_tensor_info(std::move(input_tensor_info_in)),
      output_tensor_info(std::move(output_tensor_info_in)) {}

ModelInfo::~ModelInfo() = default;

void ModelInfo::WriteIntoTrace(
    perfetto::TracedValue traced_context) const {
  [[maybe_unused]] auto dict = std::move(traced_context).WriteDictionary();
  perfetto::WriteIntoTracedValueWithFallback(
    dict.AddItem(
      "input_tensor_info"), this->input_tensor_info,
#if BUILDFLAG(MOJO_TRACE_ENABLED)
      "<value of type WTF::HashMap<WTF::String, TensorInfoPtr>>"
#else
      "<value>"
#endif  // BUILDFLAG(MOJO_TRACE_ENABLED)
    );
  perfetto::WriteIntoTracedValueWithFallback(
    dict.AddItem(
      "output_tensor_info"), this->output_tensor_info,
#if BUILDFLAG(MOJO_TRACE_ENABLED)
      "<value of type WTF::HashMap<WTF::String, TensorInfoPtr>>"
#else
      "<value>"
#endif  // BUILDFLAG(MOJO_TRACE_ENABLED)
    );
}

bool ModelInfo::Validate(
    const void* data,
    mojo::internal::ValidationContext* validation_context) {
  return Data_::Validate(data, validation_context);
}
const char ModelLoader::Name_[] = "ml.model_loader.mojom.ModelLoader";

ModelLoader::IPCStableHashFunction ModelLoader::MessageToMethodInfo_(mojo::Message& message) {
#if !BUILDFLAG(IS_FUCHSIA)
  switch (message.name()) {
    case internal::kModelLoader_Load_Name: {
      return &ModelLoader::Load_Sym::IPCStableHash;
    }
  }
#endif  // !BUILDFLAG(IS_FUCHSIA)
  return nullptr;
}


const char* ModelLoader::MessageToMethodName_(mojo::Message& message) {
#if BUILDFLAG(MOJO_TRACE_ENABLED)
  bool is_response = message.has_flag(mojo::Message::kFlagIsResponse);
  if (!is_response) {
    switch (message.name()) {
      case internal::kModelLoader_Load_Name:
            return "Receive ml::model_loader::mojom::ModelLoader::Load";
    }
  } else {
    switch (message.name()) {
      case internal::kModelLoader_Load_Name:
            return "Receive reply ml::model_loader::mojom::ModelLoader::Load";
    }
  }
  return "Receive unknown mojo message";
#else
  bool is_response = message.has_flag(mojo::Message::kFlagIsResponse);
  if (is_response) {
    return "Receive mojo reply";
  } else {
    return "Receive mojo message";
  }
#endif // BUILDFLAG(MOJO_TRACE_ENABLED)
}

#if !BUILDFLAG(IS_FUCHSIA)
uint32_t ModelLoader::Load_Sym::IPCStableHash() {
  // This method's address is used for indetifiying the mojo method name after
  // symbolization. So each IPCStableHash should have a unique address.
  // We cannot use NO_CODE_FOLDING() here - it relies on the uniqueness of
  // __LINE__ value, which is not unique accross different mojo modules.
  // The code below is very similar to NO_CODE_FOLDING, but it uses a unique
  // hash instead of __LINE__.
  constexpr uint32_t kHash = base::MD5Hash32Constexpr(
          "(Impl)ml::model_loader::mojom::ModelLoader::Load");
  const uint32_t hash = kHash;
  base::debug::Alias(&hash);
  return hash;
}
# endif // !BUILDFLAG(IS_FUCHSIA)

class ModelLoader_Load_ForwardToCallback
    : public mojo::MessageReceiver {
 public:
  ModelLoader_Load_ForwardToCallback(
      ModelLoader::LoadCallback callback
      ) : callback_(std::move(callback)) {
  }

  ModelLoader_Load_ForwardToCallback(const ModelLoader_Load_ForwardToCallback&) = delete;
  ModelLoader_Load_ForwardToCallback& operator=(const ModelLoader_Load_ForwardToCallback&) = delete;

  bool Accept(mojo::Message* message) override;
 private:
  ModelLoader::LoadCallback callback_;
};

ModelLoaderProxy::ModelLoaderProxy(mojo::MessageReceiverWithResponder* receiver)
    : receiver_(receiver) {
}

void ModelLoaderProxy::Load(
    ::mojo_base::BigBuffer in_model_content, LoadCallback callback) {
#if BUILDFLAG(MOJO_TRACE_ENABLED)
  TRACE_EVENT1(
    "mojom", "Send ml::model_loader::mojom::ModelLoader::Load", "input_parameters",
    [&](perfetto::TracedValue context){
      auto dict = std::move(context).WriteDictionary();
      perfetto::WriteIntoTracedValueWithFallback(
           dict.AddItem("model_content"), in_model_content,
                        "<value of type ::mojo_base::BigBuffer>");
   });
#endif
  const bool kExpectsResponse = true;
  const bool kIsSync = false;
  const bool kAllowInterrupt = true;
  
  const uint32_t kFlags =
      ((kExpectsResponse) ? mojo::Message::kFlagExpectsResponse : 0) |
      ((kIsSync) ? mojo::Message::kFlagIsSync : 0) |
      ((kAllowInterrupt) ? 0 : mojo::Message::kFlagNoInterrupt);
  
  mojo::Message message(
      internal::kModelLoader_Load_Name, kFlags, 0, 0, nullptr);
  mojo::internal::MessageFragment<
      ::ml::model_loader::mojom::internal::ModelLoader_Load_Params_Data> params(
          message);
  params.Allocate();
  mojo::internal::MessageFragment<decltype(params->model_content)>
      model_content_fragment(params.message());
  model_content_fragment.Claim(&params->model_content);
  mojo::internal::Serialize<::mojo_base::mojom::BigBufferDataView>(
      in_model_content, model_content_fragment, true);
  MOJO_INTERNAL_DLOG_SERIALIZATION_WARNING(
      params->model_content.is_null(),
      mojo::internal::VALIDATION_ERROR_UNEXPECTED_NULL_POINTER,
      "null model_content in ModelLoader.Load request");

#if defined(ENABLE_IPC_FUZZER)
  message.set_interface_name(ModelLoader::Name_);
  message.set_method_name("Load");
#endif
  std::unique_ptr<mojo::MessageReceiver> responder(
      new ModelLoader_Load_ForwardToCallback(
          std::move(callback)));
  ::mojo::internal::SendMojoMessage(*receiver_, message, std::move(responder));
}
class ModelLoader_Load_ProxyToResponder : public ::mojo::internal::ProxyToResponder {
 public:
  static ModelLoader::LoadCallback CreateCallback(
      ::mojo::Message& message,
      std::unique_ptr<mojo::MessageReceiverWithStatus> responder) {
    std::unique_ptr<ModelLoader_Load_ProxyToResponder> proxy(
        new ModelLoader_Load_ProxyToResponder(
            message, std::move(responder)));
    return base::BindOnce(&ModelLoader_Load_ProxyToResponder::Run,
                          std::move(proxy));
  }

  ~ModelLoader_Load_ProxyToResponder() {
#if DCHECK_IS_ON()
    if (responder_) {
      // If we're being destroyed without being run, we want to ensure the
      // binding endpoint has been closed. This checks for that asynchronously.
      // We pass a bound generated callback to handle the response so that any
      // resulting DCHECK stack will have useful interface type information.
      responder_->IsConnectedAsync(base::BindOnce(&OnIsConnectedComplete));
    }
#endif
  }

 private:
  ModelLoader_Load_ProxyToResponder(
      ::mojo::Message& message,
      std::unique_ptr<mojo::MessageReceiverWithStatus> responder)
      : ::mojo::internal::ProxyToResponder(message, std::move(responder)) {
  }

#if DCHECK_IS_ON()
  static void OnIsConnectedComplete(bool connected) {
    DCHECK(!connected)
        << "ModelLoader::LoadCallback was destroyed without "
        << "first either being run or its corresponding binding being closed. "
        << "It is an error to drop response callbacks which still correspond "
        << "to an open interface pipe.";
  }
#endif

  void Run(
      LoadModelResult in_result, ::mojo::PendingRemote<Model> in_remote, ModelInfoPtr in_model_info);
};

bool ModelLoader_Load_ForwardToCallback::Accept(
    mojo::Message* message) {

  DCHECK(message->is_serialized());
  internal::ModelLoader_Load_ResponseParams_Data* params =
      reinterpret_cast<
          internal::ModelLoader_Load_ResponseParams_Data*>(
              message->mutable_payload());
  
  bool success = true;
  LoadModelResult p_result{};
  ::mojo::PendingRemote<Model> p_remote{};
  ModelInfoPtr p_model_info{};
  ModelLoader_Load_ResponseParamsDataView input_data_view(params, message);
  
  if (success && !input_data_view.ReadResult(&p_result))
    success = false;
  if (success) {
    p_remote =
        input_data_view.TakeRemote<decltype(p_remote)>();
  }
  if (success && !input_data_view.ReadModelInfo(&p_model_info))
    success = false;
  if (!success) {
    ReportValidationErrorForMessage(
        message,
        mojo::internal::VALIDATION_ERROR_DESERIALIZATION_FAILED,
        ModelLoader::Name_, 0, true);
    return false;
  }
  if (!callback_.is_null())
    std::move(callback_).Run(
std::move(p_result), 
std::move(p_remote), 
std::move(p_model_info));
  return true;
}

void ModelLoader_Load_ProxyToResponder::Run(
    LoadModelResult in_result, ::mojo::PendingRemote<Model> in_remote, ModelInfoPtr in_model_info) {
#if BUILDFLAG(MOJO_TRACE_ENABLED)
  TRACE_EVENT1(
    "mojom", "Send reply ml::model_loader::mojom::ModelLoader::Load", "async_response_parameters",
    [&](perfetto::TracedValue context){
      auto dict = std::move(context).WriteDictionary();
      perfetto::WriteIntoTracedValueWithFallback(
           dict.AddItem("result"), in_result,
                        "<value of type LoadModelResult>");
      perfetto::WriteIntoTracedValueWithFallback(
           dict.AddItem("remote"), in_remote,
                        "<value of type ::mojo::PendingRemote<Model>>");
      perfetto::WriteIntoTracedValueWithFallback(
           dict.AddItem("model_info"), in_model_info,
                        "<value of type ModelInfoPtr>");
   });
#endif
  
  const uint32_t kFlags = mojo::Message::kFlagIsResponse |
      ((is_sync_) ? mojo::Message::kFlagIsSync : 0) |
      ((true) ? 0 : mojo::Message::kFlagNoInterrupt);
  
  mojo::Message message(
      internal::kModelLoader_Load_Name, kFlags, 0, 0, nullptr);
  mojo::internal::MessageFragment<
      ::ml::model_loader::mojom::internal::ModelLoader_Load_ResponseParams_Data> params(
          message);
  params.Allocate();
  mojo::internal::Serialize<::ml::model_loader::mojom::LoadModelResult>(
      in_result, &params->result);
  mojo::internal::Serialize<mojo::InterfacePtrDataView<::ml::model_loader::mojom::ModelInterfaceBase>>(
      in_remote, &params->remote, &params.message());
  mojo::internal::MessageFragment<
      typename decltype(params->model_info)::BaseType> model_info_fragment(
          params.message());
  mojo::internal::Serialize<::ml::model_loader::mojom::ModelInfoDataView>(
      in_model_info, model_info_fragment);
  params->model_info.Set(
      model_info_fragment.is_null() ? nullptr : model_info_fragment.data());

#if defined(ENABLE_IPC_FUZZER)
  message.set_interface_name(ModelLoader::Name_);
  message.set_method_name("Load");
#endif

  message.set_request_id(request_id_);
  message.set_trace_nonce(trace_nonce_);
  ::mojo::internal::SendMojoMessage(*responder_, message);
  // SendMojoMessage() fails silently if the responder connection is closed,
  // or if the message is malformed.
  //
  // TODO(darin): If Accept() returns false due to a malformed message, that
  // may be good reason to close the connection. However, we don't have a
  // way to do that from here. We should add a way.
  responder_ = nullptr;
}

// static
bool ModelLoaderStubDispatch::Accept(
    ModelLoader* impl,
    mojo::Message* message) {
  switch (message->header()->name) {
    case internal::kModelLoader_Load_Name: {
      break;
    }
  }
  return false;
}

// static
bool ModelLoaderStubDispatch::AcceptWithResponder(
    ModelLoader* impl,
    mojo::Message* message,
    std::unique_ptr<mojo::MessageReceiverWithStatus> responder) {
  [[maybe_unused]] const bool message_is_sync =
      message->has_flag(mojo::Message::kFlagIsSync);
  [[maybe_unused]] const uint64_t request_id = message->request_id();
  switch (message->header()->name) {
    case internal::kModelLoader_Load_Name: {

      internal::ModelLoader_Load_Params_Data* params =
          reinterpret_cast<
              internal::ModelLoader_Load_Params_Data*>(
                  message->mutable_payload());
      
      bool success = true;
      ::mojo_base::BigBuffer p_model_content{};
      ModelLoader_Load_ParamsDataView input_data_view(params, message);
      
      if (success && !input_data_view.ReadModelContent(&p_model_content))
        success = false;
      if (!success) {
        ReportValidationErrorForMessage(
            message,
            mojo::internal::VALIDATION_ERROR_DESERIALIZATION_FAILED,
            ModelLoader::Name_, 0, false);
        return false;
      }
      ModelLoader::LoadCallback callback =
          ModelLoader_Load_ProxyToResponder::CreateCallback(
              *message, std::move(responder));
      // A null |impl| means no implementation was bound.
      DCHECK(impl);
      impl->Load(
std::move(p_model_content), std::move(callback));
      return true;
    }
  }
  return false;
}


static const mojo::internal::GenericValidationInfo kModelLoaderValidationInfo[] = {
    {&internal::ModelLoader_Load_Params_Data::Validate,
     &internal::ModelLoader_Load_ResponseParams_Data::Validate},
};

bool ModelLoaderRequestValidator::Accept(mojo::Message* message) {
  const char* name = ::ml::model_loader::mojom::blink::ModelLoader::Name_;
  return mojo::internal::ValidateRequestGenericPacked(message, name, kModelLoaderValidationInfo);
}

bool ModelLoaderResponseValidator::Accept(mojo::Message* message) {
  const char* name = ::ml::model_loader::mojom::blink::ModelLoader::Name_;
  return mojo::internal::ValidateResponseGenericPacked(message, name, kModelLoaderValidationInfo);
}
const char Model::Name_[] = "ml.model_loader.mojom.Model";

Model::IPCStableHashFunction Model::MessageToMethodInfo_(mojo::Message& message) {
#if !BUILDFLAG(IS_FUCHSIA)
  switch (message.name()) {
    case internal::kModel_Compute_Name: {
      return &Model::Compute_Sym::IPCStableHash;
    }
  }
#endif  // !BUILDFLAG(IS_FUCHSIA)
  return nullptr;
}


const char* Model::MessageToMethodName_(mojo::Message& message) {
#if BUILDFLAG(MOJO_TRACE_ENABLED)
  bool is_response = message.has_flag(mojo::Message::kFlagIsResponse);
  if (!is_response) {
    switch (message.name()) {
      case internal::kModel_Compute_Name:
            return "Receive ml::model_loader::mojom::Model::Compute";
    }
  } else {
    switch (message.name()) {
      case internal::kModel_Compute_Name:
            return "Receive reply ml::model_loader::mojom::Model::Compute";
    }
  }
  return "Receive unknown mojo message";
#else
  bool is_response = message.has_flag(mojo::Message::kFlagIsResponse);
  if (is_response) {
    return "Receive mojo reply";
  } else {
    return "Receive mojo message";
  }
#endif // BUILDFLAG(MOJO_TRACE_ENABLED)
}

#if !BUILDFLAG(IS_FUCHSIA)
uint32_t Model::Compute_Sym::IPCStableHash() {
  // This method's address is used for indetifiying the mojo method name after
  // symbolization. So each IPCStableHash should have a unique address.
  // We cannot use NO_CODE_FOLDING() here - it relies on the uniqueness of
  // __LINE__ value, which is not unique accross different mojo modules.
  // The code below is very similar to NO_CODE_FOLDING, but it uses a unique
  // hash instead of __LINE__.
  constexpr uint32_t kHash = base::MD5Hash32Constexpr(
          "(Impl)ml::model_loader::mojom::Model::Compute");
  const uint32_t hash = kHash;
  base::debug::Alias(&hash);
  return hash;
}
# endif // !BUILDFLAG(IS_FUCHSIA)

class Model_Compute_ForwardToCallback
    : public mojo::MessageReceiver {
 public:
  Model_Compute_ForwardToCallback(
      Model::ComputeCallback callback
      ) : callback_(std::move(callback)) {
  }

  Model_Compute_ForwardToCallback(const Model_Compute_ForwardToCallback&) = delete;
  Model_Compute_ForwardToCallback& operator=(const Model_Compute_ForwardToCallback&) = delete;

  bool Accept(mojo::Message* message) override;
 private:
  Model::ComputeCallback callback_;
};

ModelProxy::ModelProxy(mojo::MessageReceiverWithResponder* receiver)
    : receiver_(receiver) {
}

void ModelProxy::Compute(
    const WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>& in_input_tensors, ComputeCallback callback) {
#if BUILDFLAG(MOJO_TRACE_ENABLED)
  TRACE_EVENT1(
    "mojom", "Send ml::model_loader::mojom::Model::Compute", "input_parameters",
    [&](perfetto::TracedValue context){
      auto dict = std::move(context).WriteDictionary();
      perfetto::WriteIntoTracedValueWithFallback(
           dict.AddItem("input_tensors"), in_input_tensors,
                        "<value of type const WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>&>");
   });
#endif
  const bool kExpectsResponse = true;
  const bool kIsSync = false;
  const bool kAllowInterrupt = true;
  
  const uint32_t kFlags =
      ((kExpectsResponse) ? mojo::Message::kFlagExpectsResponse : 0) |
      ((kIsSync) ? mojo::Message::kFlagIsSync : 0) |
      ((kAllowInterrupt) ? 0 : mojo::Message::kFlagNoInterrupt);
  
  mojo::Message message(
      internal::kModel_Compute_Name, kFlags, 0, 0, nullptr);
  mojo::internal::MessageFragment<
      ::ml::model_loader::mojom::internal::Model_Compute_Params_Data> params(
          message);
  params.Allocate();
  mojo::internal::MessageFragment<
      typename decltype(params->input_tensors)::BaseType>
      input_tensors_fragment(params.message());
  const mojo::internal::ContainerValidateParams input_tensors_validate_params(
      new mojo::internal::ContainerValidateParams(0, false, new mojo::internal::ContainerValidateParams(0, false, nullptr)), new mojo::internal::ContainerValidateParams(0, false, new mojo::internal::ContainerValidateParams(0, false, nullptr)));
  mojo::internal::Serialize<mojo::MapDataView<mojo::StringDataView, mojo::ArrayDataView<uint8_t>>>(
      in_input_tensors, input_tensors_fragment, &input_tensors_validate_params);
  params->input_tensors.Set(
      input_tensors_fragment.is_null() ? nullptr : input_tensors_fragment.data());
  MOJO_INTERNAL_DLOG_SERIALIZATION_WARNING(
      params->input_tensors.is_null(),
      mojo::internal::VALIDATION_ERROR_UNEXPECTED_NULL_POINTER,
      "null input_tensors in Model.Compute request");

#if defined(ENABLE_IPC_FUZZER)
  message.set_interface_name(Model::Name_);
  message.set_method_name("Compute");
#endif
  std::unique_ptr<mojo::MessageReceiver> responder(
      new Model_Compute_ForwardToCallback(
          std::move(callback)));
  ::mojo::internal::SendMojoMessage(*receiver_, message, std::move(responder));
}
class Model_Compute_ProxyToResponder : public ::mojo::internal::ProxyToResponder {
 public:
  static Model::ComputeCallback CreateCallback(
      ::mojo::Message& message,
      std::unique_ptr<mojo::MessageReceiverWithStatus> responder) {
    std::unique_ptr<Model_Compute_ProxyToResponder> proxy(
        new Model_Compute_ProxyToResponder(
            message, std::move(responder)));
    return base::BindOnce(&Model_Compute_ProxyToResponder::Run,
                          std::move(proxy));
  }

  ~Model_Compute_ProxyToResponder() {
#if DCHECK_IS_ON()
    if (responder_) {
      // If we're being destroyed without being run, we want to ensure the
      // binding endpoint has been closed. This checks for that asynchronously.
      // We pass a bound generated callback to handle the response so that any
      // resulting DCHECK stack will have useful interface type information.
      responder_->IsConnectedAsync(base::BindOnce(&OnIsConnectedComplete));
    }
#endif
  }

 private:
  Model_Compute_ProxyToResponder(
      ::mojo::Message& message,
      std::unique_ptr<mojo::MessageReceiverWithStatus> responder)
      : ::mojo::internal::ProxyToResponder(message, std::move(responder)) {
  }

#if DCHECK_IS_ON()
  static void OnIsConnectedComplete(bool connected) {
    DCHECK(!connected)
        << "Model::ComputeCallback was destroyed without "
        << "first either being run or its corresponding binding being closed. "
        << "It is an error to drop response callbacks which still correspond "
        << "to an open interface pipe.";
  }
#endif

  void Run(
      ComputeResult in_result, const absl::optional<WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>>& in_output_tensors);
};

bool Model_Compute_ForwardToCallback::Accept(
    mojo::Message* message) {

  DCHECK(message->is_serialized());
  internal::Model_Compute_ResponseParams_Data* params =
      reinterpret_cast<
          internal::Model_Compute_ResponseParams_Data*>(
              message->mutable_payload());
  
  bool success = true;
  ComputeResult p_result{};
  absl::optional<WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>> p_output_tensors{};
  Model_Compute_ResponseParamsDataView input_data_view(params, message);
  
  if (success && !input_data_view.ReadResult(&p_result))
    success = false;
  if (success && !input_data_view.ReadOutputTensors(&p_output_tensors))
    success = false;
  if (!success) {
    ReportValidationErrorForMessage(
        message,
        mojo::internal::VALIDATION_ERROR_DESERIALIZATION_FAILED,
        Model::Name_, 0, true);
    return false;
  }
  if (!callback_.is_null())
    std::move(callback_).Run(
std::move(p_result), 
std::move(p_output_tensors));
  return true;
}

void Model_Compute_ProxyToResponder::Run(
    ComputeResult in_result, const absl::optional<WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>>& in_output_tensors) {
#if BUILDFLAG(MOJO_TRACE_ENABLED)
  TRACE_EVENT1(
    "mojom", "Send reply ml::model_loader::mojom::Model::Compute", "async_response_parameters",
    [&](perfetto::TracedValue context){
      auto dict = std::move(context).WriteDictionary();
      perfetto::WriteIntoTracedValueWithFallback(
           dict.AddItem("result"), in_result,
                        "<value of type ComputeResult>");
      perfetto::WriteIntoTracedValueWithFallback(
           dict.AddItem("output_tensors"), in_output_tensors,
                        "<value of type const absl::optional<WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>>&>");
   });
#endif
  
  const uint32_t kFlags = mojo::Message::kFlagIsResponse |
      ((is_sync_) ? mojo::Message::kFlagIsSync : 0) |
      ((true) ? 0 : mojo::Message::kFlagNoInterrupt);
  
  mojo::Message message(
      internal::kModel_Compute_Name, kFlags, 0, 0, nullptr);
  mojo::internal::MessageFragment<
      ::ml::model_loader::mojom::internal::Model_Compute_ResponseParams_Data> params(
          message);
  params.Allocate();
  mojo::internal::Serialize<::ml::model_loader::mojom::ComputeResult>(
      in_result, &params->result);
  mojo::internal::MessageFragment<
      typename decltype(params->output_tensors)::BaseType>
      output_tensors_fragment(params.message());
  const mojo::internal::ContainerValidateParams output_tensors_validate_params(
      new mojo::internal::ContainerValidateParams(0, false, new mojo::internal::ContainerValidateParams(0, false, nullptr)), new mojo::internal::ContainerValidateParams(0, false, new mojo::internal::ContainerValidateParams(0, false, nullptr)));
  mojo::internal::Serialize<mojo::MapDataView<mojo::StringDataView, mojo::ArrayDataView<uint8_t>>>(
      in_output_tensors, output_tensors_fragment, &output_tensors_validate_params);
  params->output_tensors.Set(
      output_tensors_fragment.is_null() ? nullptr : output_tensors_fragment.data());

#if defined(ENABLE_IPC_FUZZER)
  message.set_interface_name(Model::Name_);
  message.set_method_name("Compute");
#endif

  message.set_request_id(request_id_);
  message.set_trace_nonce(trace_nonce_);
  ::mojo::internal::SendMojoMessage(*responder_, message);
  // SendMojoMessage() fails silently if the responder connection is closed,
  // or if the message is malformed.
  //
  // TODO(darin): If Accept() returns false due to a malformed message, that
  // may be good reason to close the connection. However, we don't have a
  // way to do that from here. We should add a way.
  responder_ = nullptr;
}

// static
bool ModelStubDispatch::Accept(
    Model* impl,
    mojo::Message* message) {
  switch (message->header()->name) {
    case internal::kModel_Compute_Name: {
      break;
    }
  }
  return false;
}

// static
bool ModelStubDispatch::AcceptWithResponder(
    Model* impl,
    mojo::Message* message,
    std::unique_ptr<mojo::MessageReceiverWithStatus> responder) {
  [[maybe_unused]] const bool message_is_sync =
      message->has_flag(mojo::Message::kFlagIsSync);
  [[maybe_unused]] const uint64_t request_id = message->request_id();
  switch (message->header()->name) {
    case internal::kModel_Compute_Name: {

      internal::Model_Compute_Params_Data* params =
          reinterpret_cast<
              internal::Model_Compute_Params_Data*>(
                  message->mutable_payload());
      
      bool success = true;
      WTF::HashMap<WTF::String, WTF::Vector<uint8_t>> p_input_tensors{};
      Model_Compute_ParamsDataView input_data_view(params, message);
      
      if (success && !input_data_view.ReadInputTensors(&p_input_tensors))
        success = false;
      if (!success) {
        ReportValidationErrorForMessage(
            message,
            mojo::internal::VALIDATION_ERROR_DESERIALIZATION_FAILED,
            Model::Name_, 0, false);
        return false;
      }
      Model::ComputeCallback callback =
          Model_Compute_ProxyToResponder::CreateCallback(
              *message, std::move(responder));
      // A null |impl| means no implementation was bound.
      DCHECK(impl);
      impl->Compute(
std::move(p_input_tensors), std::move(callback));
      return true;
    }
  }
  return false;
}


static const mojo::internal::GenericValidationInfo kModelValidationInfo[] = {
    {&internal::Model_Compute_Params_Data::Validate,
     &internal::Model_Compute_ResponseParams_Data::Validate},
};

bool ModelRequestValidator::Accept(mojo::Message* message) {
  const char* name = ::ml::model_loader::mojom::blink::Model::Name_;
  return mojo::internal::ValidateRequestGenericPacked(message, name, kModelValidationInfo);
}

bool ModelResponseValidator::Accept(mojo::Message* message) {
  const char* name = ::ml::model_loader::mojom::blink::Model::Name_;
  return mojo::internal::ValidateResponseGenericPacked(message, name, kModelValidationInfo);
}


}  // namespace blink
}  // namespace mojom
}  // namespace model_loader
}  // namespace ml


namespace mojo {


// static
bool StructTraits<::ml::model_loader::mojom::blink::CreateModelLoaderOptions::DataView, ::ml::model_loader::mojom::blink::CreateModelLoaderOptionsPtr>::Read(
    ::ml::model_loader::mojom::blink::CreateModelLoaderOptions::DataView input,
    ::ml::model_loader::mojom::blink::CreateModelLoaderOptionsPtr* output) {
  bool success = true;
  ::ml::model_loader::mojom::blink::CreateModelLoaderOptionsPtr result(::ml::model_loader::mojom::blink::CreateModelLoaderOptions::New());
  
      if (success)
        result->num_threads = input.num_threads();
      if (success && !input.ReadModelFormat(&result->model_format))
        success = false;
      if (success && !input.ReadDevicePreference(&result->device_preference))
        success = false;
  *output = std::move(result);
  return success;
}


// static
bool StructTraits<::ml::model_loader::mojom::blink::TensorInfo::DataView, ::ml::model_loader::mojom::blink::TensorInfoPtr>::Read(
    ::ml::model_loader::mojom::blink::TensorInfo::DataView input,
    ::ml::model_loader::mojom::blink::TensorInfoPtr* output) {
  bool success = true;
  ::ml::model_loader::mojom::blink::TensorInfoPtr result(::ml::model_loader::mojom::blink::TensorInfo::New());
  
      if (success)
        result->byte_size = input.byte_size();
      if (success && !input.ReadDataType(&result->data_type))
        success = false;
      if (success && !input.ReadDimensions(&result->dimensions))
        success = false;
  *output = std::move(result);
  return success;
}


// static
bool StructTraits<::ml::model_loader::mojom::blink::ModelInfo::DataView, ::ml::model_loader::mojom::blink::ModelInfoPtr>::Read(
    ::ml::model_loader::mojom::blink::ModelInfo::DataView input,
    ::ml::model_loader::mojom::blink::ModelInfoPtr* output) {
  bool success = true;
  ::ml::model_loader::mojom::blink::ModelInfoPtr result(::ml::model_loader::mojom::blink::ModelInfo::New());
  
      if (success && !input.ReadInputTensorInfo(&result->input_tensor_info))
        success = false;
      if (success && !input.ReadOutputTensorInfo(&result->output_tensor_info))
        success = false;
  *output = std::move(result);
  return success;
}

}  // namespace mojo


// Symbols declared in the -test-utils.h header are defined here instead of a
// separate .cc file to save compile time.


namespace ml {
namespace model_loader {
namespace mojom {
namespace blink {


void ModelLoaderInterceptorForTesting::Load(::mojo_base::BigBuffer model_content, LoadCallback callback) {
  GetForwardingInterface()->Load(std::move(model_content), std::move(callback));
}
ModelLoaderAsyncWaiter::ModelLoaderAsyncWaiter(
    ModelLoader* proxy) : proxy_(proxy) {}

ModelLoaderAsyncWaiter::~ModelLoaderAsyncWaiter() = default;

void ModelLoaderAsyncWaiter::Load(
    ::mojo_base::BigBuffer model_content, LoadModelResult* out_result, ::mojo::PendingRemote<Model>* out_remote, ModelInfoPtr* out_model_info) {
  base::RunLoop loop;
  proxy_->Load(std::move(model_content),
      base::BindOnce(
          [](base::RunLoop* loop,
             LoadModelResult* out_result
,
             ::mojo::PendingRemote<Model>* out_remote
,
             ModelInfoPtr* out_model_info
,
             LoadModelResult result,
             ::mojo::PendingRemote<Model> remote,
             ModelInfoPtr model_info) {*out_result = std::move(result);*out_remote = std::move(remote);*out_model_info = std::move(model_info);
            loop->Quit();
          },
          &loop,
          out_result,
          out_remote,
          out_model_info));
  loop.Run();
}



void ModelInterceptorForTesting::Compute(const WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>& input_tensors, ComputeCallback callback) {
  GetForwardingInterface()->Compute(std::move(input_tensors), std::move(callback));
}
ModelAsyncWaiter::ModelAsyncWaiter(
    Model* proxy) : proxy_(proxy) {}

ModelAsyncWaiter::~ModelAsyncWaiter() = default;

void ModelAsyncWaiter::Compute(
    const WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>& input_tensors, ComputeResult* out_result, absl::optional<WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>>* out_output_tensors) {
  base::RunLoop loop;
  proxy_->Compute(std::move(input_tensors),
      base::BindOnce(
          [](base::RunLoop* loop,
             ComputeResult* out_result
,
             absl::optional<WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>>* out_output_tensors
,
             ComputeResult result,
             const absl::optional<WTF::HashMap<WTF::String, WTF::Vector<uint8_t>>>& output_tensors) {*out_result = std::move(result);*out_output_tensors = std::move(output_tensors);
            loop->Quit();
          },
          &loop,
          out_result,
          out_output_tensors));
  loop.Run();
}





}  // namespace blink
}  // namespace mojom
}  // namespace model_loader
}  // namespace ml


#if defined(__clang__)
#pragma clang diagnostic pop
#endif