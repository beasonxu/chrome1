// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: quantized_nn_classifier.proto

#include "quantized_nn_classifier.pb.h"

#include <algorithm>

#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/extension_set.h>
#include <google/protobuf/wire_format_lite.h>
#include <google/protobuf/io/zero_copy_stream_impl_lite.h>
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>

PROTOBUF_PRAGMA_INIT_SEG

namespace _pb = ::PROTOBUF_NAMESPACE_ID;
namespace _pbi = _pb::internal;

namespace assist_ranker {
PROTOBUF_CONSTEXPR QuantizedNNLayer::QuantizedNNLayer(
    ::_pbi::ConstantInitialized)
  : weights_()
  , biases_(&::_pbi::fixed_address_empty_string, ::_pbi::ConstantInitialized{})
  , low_(0)
  , high_(0){}
struct QuantizedNNLayerDefaultTypeInternal {
  PROTOBUF_CONSTEXPR QuantizedNNLayerDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~QuantizedNNLayerDefaultTypeInternal() {}
  union {
    QuantizedNNLayer _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT_WITH_PTR PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 QuantizedNNLayerDefaultTypeInternal _QuantizedNNLayer_default_instance_;
PROTOBUF_CONSTEXPR QuantizedNNClassifierModel::QuantizedNNClassifierModel(
    ::_pbi::ConstantInitialized)
  : hidden_layer_(nullptr)
  , logits_layer_(nullptr){}
struct QuantizedNNClassifierModelDefaultTypeInternal {
  PROTOBUF_CONSTEXPR QuantizedNNClassifierModelDefaultTypeInternal()
      : _instance(::_pbi::ConstantInitialized{}) {}
  ~QuantizedNNClassifierModelDefaultTypeInternal() {}
  union {
    QuantizedNNClassifierModel _instance;
  };
};
PROTOBUF_ATTRIBUTE_NO_DESTROY PROTOBUF_CONSTINIT_WITH_PTR PROTOBUF_ATTRIBUTE_INIT_PRIORITY1 QuantizedNNClassifierModelDefaultTypeInternal _QuantizedNNClassifierModel_default_instance_;
}  // namespace assist_ranker
namespace assist_ranker {

// ===================================================================

class QuantizedNNLayer::_Internal {
 public:
  using HasBits = decltype(std::declval<QuantizedNNLayer>()._has_bits_);
  static void set_has_biases(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static void set_has_low(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
  static void set_has_high(HasBits* has_bits) {
    (*has_bits)[0] |= 4u;
  }
};

QuantizedNNLayer::QuantizedNNLayer(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::MessageLite(arena, is_message_owned),
  weights_(arena) {
  SharedCtor();
  // @@protoc_insertion_point(arena_constructor:assist_ranker.QuantizedNNLayer)
}
QuantizedNNLayer::QuantizedNNLayer(const QuantizedNNLayer& from)
  : ::PROTOBUF_NAMESPACE_ID::MessageLite(),
      _has_bits_(from._has_bits_),
      weights_(from.weights_) {
  _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
  biases_.InitDefault();
  #ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
    biases_.Set("", GetArenaForAllocation());
  #endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (from._internal_has_biases()) {
    biases_.Set(from._internal_biases(), 
      GetArenaForAllocation());
  }
  ::memcpy(&low_, &from.low_,
    static_cast<size_t>(reinterpret_cast<char*>(&high_) -
    reinterpret_cast<char*>(&low_)) + sizeof(high_));
  // @@protoc_insertion_point(copy_constructor:assist_ranker.QuantizedNNLayer)
}

inline void QuantizedNNLayer::SharedCtor() {
biases_.InitDefault();
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  biases_.Set("", GetArenaForAllocation());
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&low_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&high_) -
    reinterpret_cast<char*>(&low_)) + sizeof(high_));
}

QuantizedNNLayer::~QuantizedNNLayer() {
  // @@protoc_insertion_point(destructor:assist_ranker.QuantizedNNLayer)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<std::string>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void QuantizedNNLayer::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  biases_.Destroy();
}

void QuantizedNNLayer::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void QuantizedNNLayer::Clear() {
// @@protoc_insertion_point(message_clear_start:assist_ranker.QuantizedNNLayer)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  weights_.Clear();
  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000001u) {
    biases_.ClearNonDefaultToEmpty();
  }
  if (cached_has_bits & 0x00000006u) {
    ::memset(&low_, 0, static_cast<size_t>(
        reinterpret_cast<char*>(&high_) -
        reinterpret_cast<char*>(&low_)) + sizeof(high_));
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear<std::string>();
}

const char* QuantizedNNLayer::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // repeated bytes weights = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr -= 1;
          do {
            ptr += 1;
            auto str = _internal_add_weights();
            ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
            CHK_(ptr);
            if (!ctx->DataAvailable(ptr)) break;
          } while (::PROTOBUF_NAMESPACE_ID::internal::ExpectTag<10>(ptr));
        } else
          goto handle_unusual;
        continue;
      // optional bytes biases = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          auto str = _internal_mutable_biases();
          ptr = ::_pbi::InlineGreedyStringParser(str, ptr, ctx);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional float low = 3;
      case 3:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 29)) {
          _Internal::set_has_low(&has_bits);
          low_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      // optional float high = 4;
      case 4:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 37)) {
          _Internal::set_has_high(&has_bits);
          high_ = ::PROTOBUF_NAMESPACE_ID::internal::UnalignedLoad<float>(ptr);
          ptr += sizeof(float);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<std::string>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* QuantizedNNLayer::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:assist_ranker.QuantizedNNLayer)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  // repeated bytes weights = 1;
  for (int i = 0, n = this->_internal_weights_size(); i < n; i++) {
    const auto& s = this->_internal_weights(i);
    target = stream->WriteBytes(1, s, target);
  }

  cached_has_bits = _has_bits_[0];
  // optional bytes biases = 2;
  if (cached_has_bits & 0x00000001u) {
    target = stream->WriteBytesMaybeAliased(
        2, this->_internal_biases(), target);
  }

  // optional float low = 3;
  if (cached_has_bits & 0x00000002u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(3, this->_internal_low(), target);
  }

  // optional float high = 4;
  if (cached_has_bits & 0x00000004u) {
    target = stream->EnsureSpace(target);
    target = ::_pbi::WireFormatLite::WriteFloatToArray(4, this->_internal_high(), target);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = stream->WriteRaw(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).data(),
        static_cast<int>(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:assist_ranker.QuantizedNNLayer)
  return target;
}

size_t QuantizedNNLayer::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:assist_ranker.QuantizedNNLayer)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  // repeated bytes weights = 1;
  total_size += 1 *
      ::PROTOBUF_NAMESPACE_ID::internal::FromIntSize(weights_.size());
  for (int i = 0, n = weights_.size(); i < n; i++) {
    total_size += ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(
      weights_.Get(i));
  }

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    // optional bytes biases = 2;
    if (cached_has_bits & 0x00000001u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::BytesSize(
          this->_internal_biases());
    }

    // optional float low = 3;
    if (cached_has_bits & 0x00000002u) {
      total_size += 1 + 4;
    }

    // optional float high = 4;
    if (cached_has_bits & 0x00000004u) {
      total_size += 1 + 4;
    }

  }
  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    total_size += _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size();
  }
  int cached_size = ::_pbi::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void QuantizedNNLayer::CheckTypeAndMergeFrom(
    const ::PROTOBUF_NAMESPACE_ID::MessageLite& from) {
  MergeFrom(*::_pbi::DownCast<const QuantizedNNLayer*>(
      &from));
}

void QuantizedNNLayer::MergeFrom(const QuantizedNNLayer& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:assist_ranker.QuantizedNNLayer)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  weights_.MergeFrom(from.weights_);
  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 0x00000007u) {
    if (cached_has_bits & 0x00000001u) {
      _internal_set_biases(from._internal_biases());
    }
    if (cached_has_bits & 0x00000002u) {
      low_ = from.low_;
    }
    if (cached_has_bits & 0x00000004u) {
      high_ = from.high_;
    }
    _has_bits_[0] |= cached_has_bits;
  }
  _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
}

void QuantizedNNLayer::CopyFrom(const QuantizedNNLayer& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:assist_ranker.QuantizedNNLayer)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool QuantizedNNLayer::IsInitialized() const {
  return true;
}

void QuantizedNNLayer::InternalSwap(QuantizedNNLayer* other) {
  using std::swap;
  auto* lhs_arena = GetArenaForAllocation();
  auto* rhs_arena = other->GetArenaForAllocation();
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  weights_.InternalSwap(&other->weights_);
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr::InternalSwap(
      &biases_, lhs_arena,
      &other->biases_, rhs_arena
  );
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(QuantizedNNLayer, high_)
      + sizeof(QuantizedNNLayer::high_)
      - PROTOBUF_FIELD_OFFSET(QuantizedNNLayer, low_)>(
          reinterpret_cast<char*>(&low_),
          reinterpret_cast<char*>(&other->low_));
}

std::string QuantizedNNLayer::GetTypeName() const {
  return "assist_ranker.QuantizedNNLayer";
}


// ===================================================================

class QuantizedNNClassifierModel::_Internal {
 public:
  using HasBits = decltype(std::declval<QuantizedNNClassifierModel>()._has_bits_);
  static const ::assist_ranker::QuantizedNNLayer& hidden_layer(const QuantizedNNClassifierModel* msg);
  static void set_has_hidden_layer(HasBits* has_bits) {
    (*has_bits)[0] |= 1u;
  }
  static const ::assist_ranker::QuantizedNNLayer& logits_layer(const QuantizedNNClassifierModel* msg);
  static void set_has_logits_layer(HasBits* has_bits) {
    (*has_bits)[0] |= 2u;
  }
};

const ::assist_ranker::QuantizedNNLayer&
QuantizedNNClassifierModel::_Internal::hidden_layer(const QuantizedNNClassifierModel* msg) {
  return *msg->hidden_layer_;
}
const ::assist_ranker::QuantizedNNLayer&
QuantizedNNClassifierModel::_Internal::logits_layer(const QuantizedNNClassifierModel* msg) {
  return *msg->logits_layer_;
}
QuantizedNNClassifierModel::QuantizedNNClassifierModel(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                         bool is_message_owned)
  : ::PROTOBUF_NAMESPACE_ID::MessageLite(arena, is_message_owned) {
  SharedCtor();
  // @@protoc_insertion_point(arena_constructor:assist_ranker.QuantizedNNClassifierModel)
}
QuantizedNNClassifierModel::QuantizedNNClassifierModel(const QuantizedNNClassifierModel& from)
  : ::PROTOBUF_NAMESPACE_ID::MessageLite(),
      _has_bits_(from._has_bits_) {
  _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
  if (from._internal_has_hidden_layer()) {
    hidden_layer_ = new ::assist_ranker::QuantizedNNLayer(*from.hidden_layer_);
  } else {
    hidden_layer_ = nullptr;
  }
  if (from._internal_has_logits_layer()) {
    logits_layer_ = new ::assist_ranker::QuantizedNNLayer(*from.logits_layer_);
  } else {
    logits_layer_ = nullptr;
  }
  // @@protoc_insertion_point(copy_constructor:assist_ranker.QuantizedNNClassifierModel)
}

inline void QuantizedNNClassifierModel::SharedCtor() {
::memset(reinterpret_cast<char*>(this) + static_cast<size_t>(
    reinterpret_cast<char*>(&hidden_layer_) - reinterpret_cast<char*>(this)),
    0, static_cast<size_t>(reinterpret_cast<char*>(&logits_layer_) -
    reinterpret_cast<char*>(&hidden_layer_)) + sizeof(logits_layer_));
}

QuantizedNNClassifierModel::~QuantizedNNClassifierModel() {
  // @@protoc_insertion_point(destructor:assist_ranker.QuantizedNNClassifierModel)
  if (auto *arena = _internal_metadata_.DeleteReturnArena<std::string>()) {
  (void)arena;
    return;
  }
  SharedDtor();
}

inline void QuantizedNNClassifierModel::SharedDtor() {
  GOOGLE_DCHECK(GetArenaForAllocation() == nullptr);
  if (this != internal_default_instance()) delete hidden_layer_;
  if (this != internal_default_instance()) delete logits_layer_;
}

void QuantizedNNClassifierModel::SetCachedSize(int size) const {
  _cached_size_.Set(size);
}

void QuantizedNNClassifierModel::Clear() {
// @@protoc_insertion_point(message_clear_start:assist_ranker.QuantizedNNClassifierModel)
  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      GOOGLE_DCHECK(hidden_layer_ != nullptr);
      hidden_layer_->Clear();
    }
    if (cached_has_bits & 0x00000002u) {
      GOOGLE_DCHECK(logits_layer_ != nullptr);
      logits_layer_->Clear();
    }
  }
  _has_bits_.Clear();
  _internal_metadata_.Clear<std::string>();
}

const char* QuantizedNNClassifierModel::_InternalParse(const char* ptr, ::_pbi::ParseContext* ctx) {
#define CHK_(x) if (PROTOBUF_PREDICT_FALSE(!(x))) goto failure
  _Internal::HasBits has_bits{};
  while (!ctx->Done(&ptr)) {
    uint32_t tag;
    ptr = ::_pbi::ReadTag(ptr, &tag);
    switch (tag >> 3) {
      // optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
      case 1:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 10)) {
          ptr = ctx->ParseMessage(_internal_mutable_hidden_layer(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      // optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
      case 2:
        if (PROTOBUF_PREDICT_TRUE(static_cast<uint8_t>(tag) == 18)) {
          ptr = ctx->ParseMessage(_internal_mutable_logits_layer(), ptr);
          CHK_(ptr);
        } else
          goto handle_unusual;
        continue;
      default:
        goto handle_unusual;
    }  // switch
  handle_unusual:
    if ((tag == 0) || ((tag & 7) == 4)) {
      CHK_(ptr);
      ctx->SetLastTag(tag);
      goto message_done;
    }
    ptr = UnknownFieldParse(
        tag,
        _internal_metadata_.mutable_unknown_fields<std::string>(),
        ptr, ctx);
    CHK_(ptr != nullptr);
  }  // while
message_done:
  _has_bits_.Or(has_bits);
  return ptr;
failure:
  ptr = nullptr;
  goto message_done;
#undef CHK_
}

uint8_t* QuantizedNNClassifierModel::_InternalSerialize(
    uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const {
  // @@protoc_insertion_point(serialize_to_array_start:assist_ranker.QuantizedNNClassifierModel)
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  // optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
  if (cached_has_bits & 0x00000001u) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(1, _Internal::hidden_layer(this),
        _Internal::hidden_layer(this).GetCachedSize(), target, stream);
  }

  // optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
  if (cached_has_bits & 0x00000002u) {
    target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::
      InternalWriteMessage(2, _Internal::logits_layer(this),
        _Internal::logits_layer(this).GetCachedSize(), target, stream);
  }

  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    target = stream->WriteRaw(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).data(),
        static_cast<int>(_internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size()), target);
  }
  // @@protoc_insertion_point(serialize_to_array_end:assist_ranker.QuantizedNNClassifierModel)
  return target;
}

size_t QuantizedNNClassifierModel::ByteSizeLong() const {
// @@protoc_insertion_point(message_byte_size_start:assist_ranker.QuantizedNNClassifierModel)
  size_t total_size = 0;

  uint32_t cached_has_bits = 0;
  // Prevent compiler warnings about cached_has_bits being unused
  (void) cached_has_bits;

  cached_has_bits = _has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    // optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
    if (cached_has_bits & 0x00000001u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *hidden_layer_);
    }

    // optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
    if (cached_has_bits & 0x00000002u) {
      total_size += 1 +
        ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::MessageSize(
          *logits_layer_);
    }

  }
  if (PROTOBUF_PREDICT_FALSE(_internal_metadata_.have_unknown_fields())) {
    total_size += _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString).size();
  }
  int cached_size = ::_pbi::ToCachedSize(total_size);
  SetCachedSize(cached_size);
  return total_size;
}

void QuantizedNNClassifierModel::CheckTypeAndMergeFrom(
    const ::PROTOBUF_NAMESPACE_ID::MessageLite& from) {
  MergeFrom(*::_pbi::DownCast<const QuantizedNNClassifierModel*>(
      &from));
}

void QuantizedNNClassifierModel::MergeFrom(const QuantizedNNClassifierModel& from) {
// @@protoc_insertion_point(class_specific_merge_from_start:assist_ranker.QuantizedNNClassifierModel)
  GOOGLE_DCHECK_NE(&from, this);
  uint32_t cached_has_bits = 0;
  (void) cached_has_bits;

  cached_has_bits = from._has_bits_[0];
  if (cached_has_bits & 0x00000003u) {
    if (cached_has_bits & 0x00000001u) {
      _internal_mutable_hidden_layer()->::assist_ranker::QuantizedNNLayer::MergeFrom(from._internal_hidden_layer());
    }
    if (cached_has_bits & 0x00000002u) {
      _internal_mutable_logits_layer()->::assist_ranker::QuantizedNNLayer::MergeFrom(from._internal_logits_layer());
    }
  }
  _internal_metadata_.MergeFrom<std::string>(from._internal_metadata_);
}

void QuantizedNNClassifierModel::CopyFrom(const QuantizedNNClassifierModel& from) {
// @@protoc_insertion_point(class_specific_copy_from_start:assist_ranker.QuantizedNNClassifierModel)
  if (&from == this) return;
  Clear();
  MergeFrom(from);
}

bool QuantizedNNClassifierModel::IsInitialized() const {
  return true;
}

void QuantizedNNClassifierModel::InternalSwap(QuantizedNNClassifierModel* other) {
  using std::swap;
  _internal_metadata_.InternalSwap(&other->_internal_metadata_);
  swap(_has_bits_[0], other->_has_bits_[0]);
  ::PROTOBUF_NAMESPACE_ID::internal::memswap<
      PROTOBUF_FIELD_OFFSET(QuantizedNNClassifierModel, logits_layer_)
      + sizeof(QuantizedNNClassifierModel::logits_layer_)
      - PROTOBUF_FIELD_OFFSET(QuantizedNNClassifierModel, hidden_layer_)>(
          reinterpret_cast<char*>(&hidden_layer_),
          reinterpret_cast<char*>(&other->hidden_layer_));
}

std::string QuantizedNNClassifierModel::GetTypeName() const {
  return "assist_ranker.QuantizedNNClassifierModel";
}


// @@protoc_insertion_point(namespace_scope)
}  // namespace assist_ranker
PROTOBUF_NAMESPACE_OPEN
template<> PROTOBUF_NOINLINE ::assist_ranker::QuantizedNNLayer*
Arena::CreateMaybeMessage< ::assist_ranker::QuantizedNNLayer >(Arena* arena) {
  return Arena::CreateMessageInternal< ::assist_ranker::QuantizedNNLayer >(arena);
}
template<> PROTOBUF_NOINLINE ::assist_ranker::QuantizedNNClassifierModel*
Arena::CreateMaybeMessage< ::assist_ranker::QuantizedNNClassifierModel >(Arena* arena) {
  return Arena::CreateMessageInternal< ::assist_ranker::QuantizedNNClassifierModel >(arena);
}
PROTOBUF_NAMESPACE_CLOSE

// @@protoc_insertion_point(global_scope)
#include <google/protobuf/port_undef.inc>
