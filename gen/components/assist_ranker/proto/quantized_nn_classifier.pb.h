// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: quantized_nn_classifier.proto

#ifndef GOOGLE_PROTOBUF_INCLUDED_quantized_5fnn_5fclassifier_2eproto
#define GOOGLE_PROTOBUF_INCLUDED_quantized_5fnn_5fclassifier_2eproto

#include <limits>
#include <string>

#include <google/protobuf/port_def.inc>
#if PROTOBUF_VERSION < 3020000
#error This file was generated by a newer version of protoc which is
#error incompatible with your Protocol Buffer headers. Please update
#error your headers.
#endif
#if 3020000 < PROTOBUF_MIN_PROTOC_VERSION
#error This file was generated by an older version of protoc which is
#error incompatible with your Protocol Buffer headers. Please
#error regenerate this file with a newer version of protoc.
#endif

#include <google/protobuf/port_undef.inc>
#include <google/protobuf/io/coded_stream.h>
#include <google/protobuf/arena.h>
#include <google/protobuf/arenastring.h>
#include <google/protobuf/generated_message_util.h>
#include <google/protobuf/metadata_lite.h>
#include <google/protobuf/message_lite.h>
#include <google/protobuf/repeated_field.h>  // IWYU pragma: export
#include <google/protobuf/extension_set.h>  // IWYU pragma: export
// @@protoc_insertion_point(includes)
#include <google/protobuf/port_def.inc>
#define PROTOBUF_INTERNAL_EXPORT_quantized_5fnn_5fclassifier_2eproto
PROTOBUF_NAMESPACE_OPEN
namespace internal {
class AnyMetadata;
}  // namespace internal
PROTOBUF_NAMESPACE_CLOSE

// Internal implementation detail -- do not use these members.
struct TableStruct_quantized_5fnn_5fclassifier_2eproto {
  static const uint32_t offsets[];
};
namespace assist_ranker {
class QuantizedNNClassifierModel;
struct QuantizedNNClassifierModelDefaultTypeInternal;
extern QuantizedNNClassifierModelDefaultTypeInternal _QuantizedNNClassifierModel_default_instance_;
class QuantizedNNLayer;
struct QuantizedNNLayerDefaultTypeInternal;
extern QuantizedNNLayerDefaultTypeInternal _QuantizedNNLayer_default_instance_;
}  // namespace assist_ranker
PROTOBUF_NAMESPACE_OPEN
template<> ::assist_ranker::QuantizedNNClassifierModel* Arena::CreateMaybeMessage<::assist_ranker::QuantizedNNClassifierModel>(Arena*);
template<> ::assist_ranker::QuantizedNNLayer* Arena::CreateMaybeMessage<::assist_ranker::QuantizedNNLayer>(Arena*);
PROTOBUF_NAMESPACE_CLOSE
namespace assist_ranker {

// ===================================================================

class QuantizedNNLayer final :
    public ::PROTOBUF_NAMESPACE_ID::MessageLite /* @@protoc_insertion_point(class_definition:assist_ranker.QuantizedNNLayer) */ {
 public:
  inline QuantizedNNLayer() : QuantizedNNLayer(nullptr) {}
  ~QuantizedNNLayer() override;
  explicit PROTOBUF_CONSTEXPR QuantizedNNLayer(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  QuantizedNNLayer(const QuantizedNNLayer& from);
  QuantizedNNLayer(QuantizedNNLayer&& from) noexcept
    : QuantizedNNLayer() {
    *this = ::std::move(from);
  }

  inline QuantizedNNLayer& operator=(const QuantizedNNLayer& from) {
    CopyFrom(from);
    return *this;
  }
  inline QuantizedNNLayer& operator=(QuantizedNNLayer&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const std::string& unknown_fields() const {
    return _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString);
  }
  inline std::string* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields<std::string>();
  }

  static const QuantizedNNLayer& default_instance() {
    return *internal_default_instance();
  }
  static inline const QuantizedNNLayer* internal_default_instance() {
    return reinterpret_cast<const QuantizedNNLayer*>(
               &_QuantizedNNLayer_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    0;

  friend void swap(QuantizedNNLayer& a, QuantizedNNLayer& b) {
    a.Swap(&b);
  }
  PROTOBUF_NOINLINE void Swap(QuantizedNNLayer* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(QuantizedNNLayer* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  QuantizedNNLayer* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<QuantizedNNLayer>(arena);
  }
  void CheckTypeAndMergeFrom(const ::PROTOBUF_NAMESPACE_ID::MessageLite& from)  final;
  void CopyFrom(const QuantizedNNLayer& from);
  void MergeFrom(const QuantizedNNLayer& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(QuantizedNNLayer* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "assist_ranker.QuantizedNNLayer";
  }
  protected:
  explicit QuantizedNNLayer(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  std::string GetTypeName() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kWeightsFieldNumber = 1,
    kBiasesFieldNumber = 2,
    kLowFieldNumber = 3,
    kHighFieldNumber = 4,
  };
  // repeated bytes weights = 1;
  int weights_size() const;
  private:
  int _internal_weights_size() const;
  public:
  void clear_weights();
  const std::string& weights(int index) const;
  std::string* mutable_weights(int index);
  void set_weights(int index, const std::string& value);
  void set_weights(int index, std::string&& value);
  void set_weights(int index, const char* value);
  void set_weights(int index, const void* value, size_t size);
  std::string* add_weights();
  void add_weights(const std::string& value);
  void add_weights(std::string&& value);
  void add_weights(const char* value);
  void add_weights(const void* value, size_t size);
  const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>& weights() const;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>* mutable_weights();
  private:
  const std::string& _internal_weights(int index) const;
  std::string* _internal_add_weights();
  public:

  // optional bytes biases = 2;
  bool has_biases() const;
  private:
  bool _internal_has_biases() const;
  public:
  void clear_biases();
  const std::string& biases() const;
  template <typename ArgT0 = const std::string&, typename... ArgT>
  void set_biases(ArgT0&& arg0, ArgT... args);
  std::string* mutable_biases();
  PROTOBUF_NODISCARD std::string* release_biases();
  void set_allocated_biases(std::string* biases);
  private:
  const std::string& _internal_biases() const;
  inline PROTOBUF_ALWAYS_INLINE void _internal_set_biases(const std::string& value);
  std::string* _internal_mutable_biases();
  public:

  // optional float low = 3;
  bool has_low() const;
  private:
  bool _internal_has_low() const;
  public:
  void clear_low();
  float low() const;
  void set_low(float value);
  private:
  float _internal_low() const;
  void _internal_set_low(float value);
  public:

  // optional float high = 4;
  bool has_high() const;
  private:
  bool _internal_has_high() const;
  public:
  void clear_high();
  float high() const;
  void set_high(float value);
  private:
  float _internal_high() const;
  void _internal_set_high(float value);
  public:

  // @@protoc_insertion_point(class_scope:assist_ranker.QuantizedNNLayer)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::internal::HasBits<1> _has_bits_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string> weights_;
  ::PROTOBUF_NAMESPACE_ID::internal::ArenaStringPtr biases_;
  float low_;
  float high_;
  friend struct ::TableStruct_quantized_5fnn_5fclassifier_2eproto;
};
// -------------------------------------------------------------------

class QuantizedNNClassifierModel final :
    public ::PROTOBUF_NAMESPACE_ID::MessageLite /* @@protoc_insertion_point(class_definition:assist_ranker.QuantizedNNClassifierModel) */ {
 public:
  inline QuantizedNNClassifierModel() : QuantizedNNClassifierModel(nullptr) {}
  ~QuantizedNNClassifierModel() override;
  explicit PROTOBUF_CONSTEXPR QuantizedNNClassifierModel(::PROTOBUF_NAMESPACE_ID::internal::ConstantInitialized);

  QuantizedNNClassifierModel(const QuantizedNNClassifierModel& from);
  QuantizedNNClassifierModel(QuantizedNNClassifierModel&& from) noexcept
    : QuantizedNNClassifierModel() {
    *this = ::std::move(from);
  }

  inline QuantizedNNClassifierModel& operator=(const QuantizedNNClassifierModel& from) {
    CopyFrom(from);
    return *this;
  }
  inline QuantizedNNClassifierModel& operator=(QuantizedNNClassifierModel&& from) noexcept {
    if (this == &from) return *this;
    if (GetOwningArena() == from.GetOwningArena()
  #ifdef PROTOBUF_FORCE_COPY_IN_MOVE
        && GetOwningArena() != nullptr
  #endif  // !PROTOBUF_FORCE_COPY_IN_MOVE
    ) {
      InternalSwap(&from);
    } else {
      CopyFrom(from);
    }
    return *this;
  }

  inline const std::string& unknown_fields() const {
    return _internal_metadata_.unknown_fields<std::string>(::PROTOBUF_NAMESPACE_ID::internal::GetEmptyString);
  }
  inline std::string* mutable_unknown_fields() {
    return _internal_metadata_.mutable_unknown_fields<std::string>();
  }

  static const QuantizedNNClassifierModel& default_instance() {
    return *internal_default_instance();
  }
  static inline const QuantizedNNClassifierModel* internal_default_instance() {
    return reinterpret_cast<const QuantizedNNClassifierModel*>(
               &_QuantizedNNClassifierModel_default_instance_);
  }
  static constexpr int kIndexInFileMessages =
    1;

  friend void swap(QuantizedNNClassifierModel& a, QuantizedNNClassifierModel& b) {
    a.Swap(&b);
  }
  PROTOBUF_NOINLINE void Swap(QuantizedNNClassifierModel* other) {
    if (other == this) return;
  #ifdef PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() != nullptr &&
        GetOwningArena() == other->GetOwningArena()) {
   #else  // PROTOBUF_FORCE_COPY_IN_SWAP
    if (GetOwningArena() == other->GetOwningArena()) {
  #endif  // !PROTOBUF_FORCE_COPY_IN_SWAP
      InternalSwap(other);
    } else {
      ::PROTOBUF_NAMESPACE_ID::internal::GenericSwap(this, other);
    }
  }
  void UnsafeArenaSwap(QuantizedNNClassifierModel* other) {
    if (other == this) return;
    GOOGLE_DCHECK(GetOwningArena() == other->GetOwningArena());
    InternalSwap(other);
  }

  // implements Message ----------------------------------------------

  QuantizedNNClassifierModel* New(::PROTOBUF_NAMESPACE_ID::Arena* arena = nullptr) const final {
    return CreateMaybeMessage<QuantizedNNClassifierModel>(arena);
  }
  void CheckTypeAndMergeFrom(const ::PROTOBUF_NAMESPACE_ID::MessageLite& from)  final;
  void CopyFrom(const QuantizedNNClassifierModel& from);
  void MergeFrom(const QuantizedNNClassifierModel& from);
  PROTOBUF_ATTRIBUTE_REINITIALIZES void Clear() final;
  bool IsInitialized() const final;

  size_t ByteSizeLong() const final;
  const char* _InternalParse(const char* ptr, ::PROTOBUF_NAMESPACE_ID::internal::ParseContext* ctx) final;
  uint8_t* _InternalSerialize(
      uint8_t* target, ::PROTOBUF_NAMESPACE_ID::io::EpsCopyOutputStream* stream) const final;
  int GetCachedSize() const final { return _cached_size_.Get(); }

  private:
  void SharedCtor();
  void SharedDtor();
  void SetCachedSize(int size) const;
  void InternalSwap(QuantizedNNClassifierModel* other);

  private:
  friend class ::PROTOBUF_NAMESPACE_ID::internal::AnyMetadata;
  static ::PROTOBUF_NAMESPACE_ID::StringPiece FullMessageName() {
    return "assist_ranker.QuantizedNNClassifierModel";
  }
  protected:
  explicit QuantizedNNClassifierModel(::PROTOBUF_NAMESPACE_ID::Arena* arena,
                       bool is_message_owned = false);
  public:

  std::string GetTypeName() const final;

  // nested types ----------------------------------------------------

  // accessors -------------------------------------------------------

  enum : int {
    kHiddenLayerFieldNumber = 1,
    kLogitsLayerFieldNumber = 2,
  };
  // optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
  bool has_hidden_layer() const;
  private:
  bool _internal_has_hidden_layer() const;
  public:
  void clear_hidden_layer();
  const ::assist_ranker::QuantizedNNLayer& hidden_layer() const;
  PROTOBUF_NODISCARD ::assist_ranker::QuantizedNNLayer* release_hidden_layer();
  ::assist_ranker::QuantizedNNLayer* mutable_hidden_layer();
  void set_allocated_hidden_layer(::assist_ranker::QuantizedNNLayer* hidden_layer);
  private:
  const ::assist_ranker::QuantizedNNLayer& _internal_hidden_layer() const;
  ::assist_ranker::QuantizedNNLayer* _internal_mutable_hidden_layer();
  public:
  void unsafe_arena_set_allocated_hidden_layer(
      ::assist_ranker::QuantizedNNLayer* hidden_layer);
  ::assist_ranker::QuantizedNNLayer* unsafe_arena_release_hidden_layer();

  // optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
  bool has_logits_layer() const;
  private:
  bool _internal_has_logits_layer() const;
  public:
  void clear_logits_layer();
  const ::assist_ranker::QuantizedNNLayer& logits_layer() const;
  PROTOBUF_NODISCARD ::assist_ranker::QuantizedNNLayer* release_logits_layer();
  ::assist_ranker::QuantizedNNLayer* mutable_logits_layer();
  void set_allocated_logits_layer(::assist_ranker::QuantizedNNLayer* logits_layer);
  private:
  const ::assist_ranker::QuantizedNNLayer& _internal_logits_layer() const;
  ::assist_ranker::QuantizedNNLayer* _internal_mutable_logits_layer();
  public:
  void unsafe_arena_set_allocated_logits_layer(
      ::assist_ranker::QuantizedNNLayer* logits_layer);
  ::assist_ranker::QuantizedNNLayer* unsafe_arena_release_logits_layer();

  // @@protoc_insertion_point(class_scope:assist_ranker.QuantizedNNClassifierModel)
 private:
  class _Internal;

  template <typename T> friend class ::PROTOBUF_NAMESPACE_ID::Arena::InternalHelper;
  typedef void InternalArenaConstructable_;
  typedef void DestructorSkippable_;
  ::PROTOBUF_NAMESPACE_ID::internal::HasBits<1> _has_bits_;
  mutable ::PROTOBUF_NAMESPACE_ID::internal::CachedSize _cached_size_;
  ::assist_ranker::QuantizedNNLayer* hidden_layer_;
  ::assist_ranker::QuantizedNNLayer* logits_layer_;
  friend struct ::TableStruct_quantized_5fnn_5fclassifier_2eproto;
};
// ===================================================================


// ===================================================================

#ifdef __GNUC__
  #pragma GCC diagnostic push
  #pragma GCC diagnostic ignored "-Wstrict-aliasing"
#endif  // __GNUC__
// QuantizedNNLayer

// repeated bytes weights = 1;
inline int QuantizedNNLayer::_internal_weights_size() const {
  return weights_.size();
}
inline int QuantizedNNLayer::weights_size() const {
  return _internal_weights_size();
}
inline void QuantizedNNLayer::clear_weights() {
  weights_.Clear();
}
inline std::string* QuantizedNNLayer::add_weights() {
  std::string* _s = _internal_add_weights();
  // @@protoc_insertion_point(field_add_mutable:assist_ranker.QuantizedNNLayer.weights)
  return _s;
}
inline const std::string& QuantizedNNLayer::_internal_weights(int index) const {
  return weights_.Get(index);
}
inline const std::string& QuantizedNNLayer::weights(int index) const {
  // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNLayer.weights)
  return _internal_weights(index);
}
inline std::string* QuantizedNNLayer::mutable_weights(int index) {
  // @@protoc_insertion_point(field_mutable:assist_ranker.QuantizedNNLayer.weights)
  return weights_.Mutable(index);
}
inline void QuantizedNNLayer::set_weights(int index, const std::string& value) {
  weights_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::set_weights(int index, std::string&& value) {
  weights_.Mutable(index)->assign(std::move(value));
  // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::set_weights(int index, const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  weights_.Mutable(index)->assign(value);
  // @@protoc_insertion_point(field_set_char:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::set_weights(int index, const void* value, size_t size) {
  weights_.Mutable(index)->assign(
    reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_set_pointer:assist_ranker.QuantizedNNLayer.weights)
}
inline std::string* QuantizedNNLayer::_internal_add_weights() {
  return weights_.Add();
}
inline void QuantizedNNLayer::add_weights(const std::string& value) {
  weights_.Add()->assign(value);
  // @@protoc_insertion_point(field_add:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::add_weights(std::string&& value) {
  weights_.Add(std::move(value));
  // @@protoc_insertion_point(field_add:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::add_weights(const char* value) {
  GOOGLE_DCHECK(value != nullptr);
  weights_.Add()->assign(value);
  // @@protoc_insertion_point(field_add_char:assist_ranker.QuantizedNNLayer.weights)
}
inline void QuantizedNNLayer::add_weights(const void* value, size_t size) {
  weights_.Add()->assign(reinterpret_cast<const char*>(value), size);
  // @@protoc_insertion_point(field_add_pointer:assist_ranker.QuantizedNNLayer.weights)
}
inline const ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>&
QuantizedNNLayer::weights() const {
  // @@protoc_insertion_point(field_list:assist_ranker.QuantizedNNLayer.weights)
  return weights_;
}
inline ::PROTOBUF_NAMESPACE_ID::RepeatedPtrField<std::string>*
QuantizedNNLayer::mutable_weights() {
  // @@protoc_insertion_point(field_mutable_list:assist_ranker.QuantizedNNLayer.weights)
  return &weights_;
}

// optional bytes biases = 2;
inline bool QuantizedNNLayer::_internal_has_biases() const {
  bool value = (_has_bits_[0] & 0x00000001u) != 0;
  return value;
}
inline bool QuantizedNNLayer::has_biases() const {
  return _internal_has_biases();
}
inline void QuantizedNNLayer::clear_biases() {
  biases_.ClearToEmpty();
  _has_bits_[0] &= ~0x00000001u;
}
inline const std::string& QuantizedNNLayer::biases() const {
  // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNLayer.biases)
  return _internal_biases();
}
template <typename ArgT0, typename... ArgT>
inline PROTOBUF_ALWAYS_INLINE
void QuantizedNNLayer::set_biases(ArgT0&& arg0, ArgT... args) {
 _has_bits_[0] |= 0x00000001u;
 biases_.SetBytes(static_cast<ArgT0 &&>(arg0), args..., GetArenaForAllocation());
  // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.biases)
}
inline std::string* QuantizedNNLayer::mutable_biases() {
  std::string* _s = _internal_mutable_biases();
  // @@protoc_insertion_point(field_mutable:assist_ranker.QuantizedNNLayer.biases)
  return _s;
}
inline const std::string& QuantizedNNLayer::_internal_biases() const {
  return biases_.Get();
}
inline void QuantizedNNLayer::_internal_set_biases(const std::string& value) {
  _has_bits_[0] |= 0x00000001u;
  biases_.Set(value, GetArenaForAllocation());
}
inline std::string* QuantizedNNLayer::_internal_mutable_biases() {
  _has_bits_[0] |= 0x00000001u;
  return biases_.Mutable(GetArenaForAllocation());
}
inline std::string* QuantizedNNLayer::release_biases() {
  // @@protoc_insertion_point(field_release:assist_ranker.QuantizedNNLayer.biases)
  if (!_internal_has_biases()) {
    return nullptr;
  }
  _has_bits_[0] &= ~0x00000001u;
  auto* p = biases_.Release();
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (biases_.IsDefault()) {
    biases_.Set("", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  return p;
}
inline void QuantizedNNLayer::set_allocated_biases(std::string* biases) {
  if (biases != nullptr) {
    _has_bits_[0] |= 0x00000001u;
  } else {
    _has_bits_[0] &= ~0x00000001u;
  }
  biases_.SetAllocated(biases, GetArenaForAllocation());
#ifdef PROTOBUF_FORCE_COPY_DEFAULT_STRING
  if (biases_.IsDefault()) {
    biases_.Set("", GetArenaForAllocation());
  }
#endif // PROTOBUF_FORCE_COPY_DEFAULT_STRING
  // @@protoc_insertion_point(field_set_allocated:assist_ranker.QuantizedNNLayer.biases)
}

// optional float low = 3;
inline bool QuantizedNNLayer::_internal_has_low() const {
  bool value = (_has_bits_[0] & 0x00000002u) != 0;
  return value;
}
inline bool QuantizedNNLayer::has_low() const {
  return _internal_has_low();
}
inline void QuantizedNNLayer::clear_low() {
  low_ = 0;
  _has_bits_[0] &= ~0x00000002u;
}
inline float QuantizedNNLayer::_internal_low() const {
  return low_;
}
inline float QuantizedNNLayer::low() const {
  // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNLayer.low)
  return _internal_low();
}
inline void QuantizedNNLayer::_internal_set_low(float value) {
  _has_bits_[0] |= 0x00000002u;
  low_ = value;
}
inline void QuantizedNNLayer::set_low(float value) {
  _internal_set_low(value);
  // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.low)
}

// optional float high = 4;
inline bool QuantizedNNLayer::_internal_has_high() const {
  bool value = (_has_bits_[0] & 0x00000004u) != 0;
  return value;
}
inline bool QuantizedNNLayer::has_high() const {
  return _internal_has_high();
}
inline void QuantizedNNLayer::clear_high() {
  high_ = 0;
  _has_bits_[0] &= ~0x00000004u;
}
inline float QuantizedNNLayer::_internal_high() const {
  return high_;
}
inline float QuantizedNNLayer::high() const {
  // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNLayer.high)
  return _internal_high();
}
inline void QuantizedNNLayer::_internal_set_high(float value) {
  _has_bits_[0] |= 0x00000004u;
  high_ = value;
}
inline void QuantizedNNLayer::set_high(float value) {
  _internal_set_high(value);
  // @@protoc_insertion_point(field_set:assist_ranker.QuantizedNNLayer.high)
}

// -------------------------------------------------------------------

// QuantizedNNClassifierModel

// optional .assist_ranker.QuantizedNNLayer hidden_layer = 1;
inline bool QuantizedNNClassifierModel::_internal_has_hidden_layer() const {
  bool value = (_has_bits_[0] & 0x00000001u) != 0;
  PROTOBUF_ASSUME(!value || hidden_layer_ != nullptr);
  return value;
}
inline bool QuantizedNNClassifierModel::has_hidden_layer() const {
  return _internal_has_hidden_layer();
}
inline void QuantizedNNClassifierModel::clear_hidden_layer() {
  if (hidden_layer_ != nullptr) hidden_layer_->Clear();
  _has_bits_[0] &= ~0x00000001u;
}
inline const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::_internal_hidden_layer() const {
  const ::assist_ranker::QuantizedNNLayer* p = hidden_layer_;
  return p != nullptr ? *p : reinterpret_cast<const ::assist_ranker::QuantizedNNLayer&>(
      ::assist_ranker::_QuantizedNNLayer_default_instance_);
}
inline const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::hidden_layer() const {
  // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
  return _internal_hidden_layer();
}
inline void QuantizedNNClassifierModel::unsafe_arena_set_allocated_hidden_layer(
    ::assist_ranker::QuantizedNNLayer* hidden_layer) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(hidden_layer_);
  }
  hidden_layer_ = hidden_layer;
  if (hidden_layer) {
    _has_bits_[0] |= 0x00000001u;
  } else {
    _has_bits_[0] &= ~0x00000001u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::release_hidden_layer() {
  _has_bits_[0] &= ~0x00000001u;
  ::assist_ranker::QuantizedNNLayer* temp = hidden_layer_;
  hidden_layer_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::unsafe_arena_release_hidden_layer() {
  // @@protoc_insertion_point(field_release:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
  _has_bits_[0] &= ~0x00000001u;
  ::assist_ranker::QuantizedNNLayer* temp = hidden_layer_;
  hidden_layer_ = nullptr;
  return temp;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::_internal_mutable_hidden_layer() {
  _has_bits_[0] |= 0x00000001u;
  if (hidden_layer_ == nullptr) {
    auto* p = CreateMaybeMessage<::assist_ranker::QuantizedNNLayer>(GetArenaForAllocation());
    hidden_layer_ = p;
  }
  return hidden_layer_;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::mutable_hidden_layer() {
  ::assist_ranker::QuantizedNNLayer* _msg = _internal_mutable_hidden_layer();
  // @@protoc_insertion_point(field_mutable:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
  return _msg;
}
inline void QuantizedNNClassifierModel::set_allocated_hidden_layer(::assist_ranker::QuantizedNNLayer* hidden_layer) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete hidden_layer_;
  }
  if (hidden_layer) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(hidden_layer);
    if (message_arena != submessage_arena) {
      hidden_layer = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, hidden_layer, submessage_arena);
    }
    _has_bits_[0] |= 0x00000001u;
  } else {
    _has_bits_[0] &= ~0x00000001u;
  }
  hidden_layer_ = hidden_layer;
  // @@protoc_insertion_point(field_set_allocated:assist_ranker.QuantizedNNClassifierModel.hidden_layer)
}

// optional .assist_ranker.QuantizedNNLayer logits_layer = 2;
inline bool QuantizedNNClassifierModel::_internal_has_logits_layer() const {
  bool value = (_has_bits_[0] & 0x00000002u) != 0;
  PROTOBUF_ASSUME(!value || logits_layer_ != nullptr);
  return value;
}
inline bool QuantizedNNClassifierModel::has_logits_layer() const {
  return _internal_has_logits_layer();
}
inline void QuantizedNNClassifierModel::clear_logits_layer() {
  if (logits_layer_ != nullptr) logits_layer_->Clear();
  _has_bits_[0] &= ~0x00000002u;
}
inline const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::_internal_logits_layer() const {
  const ::assist_ranker::QuantizedNNLayer* p = logits_layer_;
  return p != nullptr ? *p : reinterpret_cast<const ::assist_ranker::QuantizedNNLayer&>(
      ::assist_ranker::_QuantizedNNLayer_default_instance_);
}
inline const ::assist_ranker::QuantizedNNLayer& QuantizedNNClassifierModel::logits_layer() const {
  // @@protoc_insertion_point(field_get:assist_ranker.QuantizedNNClassifierModel.logits_layer)
  return _internal_logits_layer();
}
inline void QuantizedNNClassifierModel::unsafe_arena_set_allocated_logits_layer(
    ::assist_ranker::QuantizedNNLayer* logits_layer) {
  if (GetArenaForAllocation() == nullptr) {
    delete reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(logits_layer_);
  }
  logits_layer_ = logits_layer;
  if (logits_layer) {
    _has_bits_[0] |= 0x00000002u;
  } else {
    _has_bits_[0] &= ~0x00000002u;
  }
  // @@protoc_insertion_point(field_unsafe_arena_set_allocated:assist_ranker.QuantizedNNClassifierModel.logits_layer)
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::release_logits_layer() {
  _has_bits_[0] &= ~0x00000002u;
  ::assist_ranker::QuantizedNNLayer* temp = logits_layer_;
  logits_layer_ = nullptr;
#ifdef PROTOBUF_FORCE_COPY_IN_RELEASE
  auto* old =  reinterpret_cast<::PROTOBUF_NAMESPACE_ID::MessageLite*>(temp);
  temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  if (GetArenaForAllocation() == nullptr) { delete old; }
#else  // PROTOBUF_FORCE_COPY_IN_RELEASE
  if (GetArenaForAllocation() != nullptr) {
    temp = ::PROTOBUF_NAMESPACE_ID::internal::DuplicateIfNonNull(temp);
  }
#endif  // !PROTOBUF_FORCE_COPY_IN_RELEASE
  return temp;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::unsafe_arena_release_logits_layer() {
  // @@protoc_insertion_point(field_release:assist_ranker.QuantizedNNClassifierModel.logits_layer)
  _has_bits_[0] &= ~0x00000002u;
  ::assist_ranker::QuantizedNNLayer* temp = logits_layer_;
  logits_layer_ = nullptr;
  return temp;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::_internal_mutable_logits_layer() {
  _has_bits_[0] |= 0x00000002u;
  if (logits_layer_ == nullptr) {
    auto* p = CreateMaybeMessage<::assist_ranker::QuantizedNNLayer>(GetArenaForAllocation());
    logits_layer_ = p;
  }
  return logits_layer_;
}
inline ::assist_ranker::QuantizedNNLayer* QuantizedNNClassifierModel::mutable_logits_layer() {
  ::assist_ranker::QuantizedNNLayer* _msg = _internal_mutable_logits_layer();
  // @@protoc_insertion_point(field_mutable:assist_ranker.QuantizedNNClassifierModel.logits_layer)
  return _msg;
}
inline void QuantizedNNClassifierModel::set_allocated_logits_layer(::assist_ranker::QuantizedNNLayer* logits_layer) {
  ::PROTOBUF_NAMESPACE_ID::Arena* message_arena = GetArenaForAllocation();
  if (message_arena == nullptr) {
    delete logits_layer_;
  }
  if (logits_layer) {
    ::PROTOBUF_NAMESPACE_ID::Arena* submessage_arena =
        ::PROTOBUF_NAMESPACE_ID::Arena::InternalGetOwningArena(logits_layer);
    if (message_arena != submessage_arena) {
      logits_layer = ::PROTOBUF_NAMESPACE_ID::internal::GetOwnedMessage(
          message_arena, logits_layer, submessage_arena);
    }
    _has_bits_[0] |= 0x00000002u;
  } else {
    _has_bits_[0] &= ~0x00000002u;
  }
  logits_layer_ = logits_layer;
  // @@protoc_insertion_point(field_set_allocated:assist_ranker.QuantizedNNClassifierModel.logits_layer)
}

#ifdef __GNUC__
  #pragma GCC diagnostic pop
#endif  // __GNUC__
// -------------------------------------------------------------------


// @@protoc_insertion_point(namespace_scope)

}  // namespace assist_ranker

// @@protoc_insertion_point(global_scope)

#include <google/protobuf/port_undef.inc>
#endif  // GOOGLE_PROTOBUF_INCLUDED_GOOGLE_PROTOBUF_INCLUDED_quantized_5fnn_5fclassifier_2eproto
